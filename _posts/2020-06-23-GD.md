---
title: 'Graduent Descent from Scratch in 20 Lines'
date: 2020-06-23
permalink: /posts/2020/06/gd/
tags:
  - Python
  - ML
---

How do ML algorithms optimize the loss functions? 
[This notebook](https://nbviewer.jupyter.org/github/rakash/Posts/blob/master/Gradient%20Descent%20From%20Scratch%20%281%29.ipynb) implements Gradient descent from scratch in less 20 lines of code.
